{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver = webdriver.Firefox(executable_path='C:/Users/micah/geckodriver-v0.31.0-win64/geckodriver.exe')\n",
    "def login(driver):\n",
    "    with open(\"smith.txt\", 'r') as f:\n",
    "        account = (f.read()).split(\",\")\n",
    "    driver.get(\"https://www.facebook.com/\")\n",
    "    elem = driver.find_element(By.XPATH, '//*[@id=\"email\"]')\n",
    "    elem.clear()\n",
    "    elem.send_keys(account[0])\n",
    "    passw = driver.find_element(By.XPATH,'//*[@id=\"pass\"]')\n",
    "    passw.send_keys(account[1])\n",
    "    login = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[1]/div/div/div/div[2]/div/div[1]/form/div[2]/button')\n",
    "    login.click()\n",
    "def generalNameList():\n",
    "    x = pd.read_csv('names.csv')\n",
    "    return x['Generals'].to_list()\n",
    "def nameToLink(name):\n",
    "    return name.replace(\" \", \"%20\")\n",
    "def generalSearch(driver):\n",
    "    generals = generalNameList()\n",
    "    master_list = \"\"\n",
    "    count = 0\n",
    "    for general in generals:\n",
    "        # elem = driver.find_element(By.XPATH, '/html/body/div[1]/div/div[1]/div/div[2]/div[2]/div[1]/div/div/div[3]/div/div/div/div[1]/div/div/label/input')\n",
    "        # elem.send_keys(general)\n",
    "        driver.get(\"https://www.facebook.com/search/people/?q=\" + nameToLink(general))\n",
    "        textual_healing = driver.page_source\n",
    "        expression = '\"profile\":{\"__typename\":\"User\",\"__isNode\":\"User\",\"id\":\"[0-9]*\"'\n",
    "        ids = re.findall(expression, textual_healing)\n",
    "        x = np.array(ids)\n",
    "        p = np.unique(x)\n",
    "        gen = (general + \"/\")*len(p)\n",
    "        p = \" \".join(p)\n",
    "        gen2 = gen + \";\" + p\n",
    "        master_list += str(gen2) + \"\\n\"\n",
    "        if count%15 == 0 and count != 0:\n",
    "            time.sleep(20)\n",
    "        count +=1\n",
    "    driver.close()\n",
    "    with open('general_ids.txt', 'w') as f:\n",
    "        f.write(str(master_list))\n",
    "\n",
    "# login(driver)\n",
    "# generalSearch(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFrame():\n",
    "    q = open('general_ids.txt', 'r')\n",
    "    text = q.read()\n",
    "    text = text.split(\"\\n\")\n",
    "    id_list= []\n",
    "    for tex in text:\n",
    "        general_list = tex.split(\";\")\n",
    "        general_list[0] = general_list[0].split(\"/\")\n",
    "        if len(general_list) == 2:\n",
    "            general_list[1] = general_list[1].split(\" \")\n",
    "            for i in range(len(general_list[1])):\n",
    "                general_list[1][i] = int(re.sub('\\D', '', general_list[1][i]))\n",
    "            q = list(zip(general_list[0], general_list[1]))\n",
    "        id_list.append(q)\n",
    "    actual = []\n",
    "    for item in id_list:\n",
    "        actual += item\n",
    "    hier_index = pd.DataFrame(actual, columns=['General', 'id'])\n",
    "    df = pd.DataFrame(np.zeros(len(actual)),columns=['score'])\n",
    "    df = pd.concat([hier_index, df], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = webdriver.Firefox(executable_path='C:/Users/micah/geckodriver-v0.31.0-win64/geckodriver.exe')\n",
    "# login(driver)\n",
    "# driver.get(\"https://www.facebook.com/jj.j.heck\")\n",
    "def findFriends(html):\n",
    "    rex = r'\"text\":\".*\\sfriends\"'\n",
    "    friends = re.findall(rex,html)\n",
    "    if friends == []:\n",
    "        return 0\n",
    "    hell = re.findall(r'(\\d+(?:\\.\\d+)?)', friends[0])\n",
    "    if 'K' in friends[0]:\n",
    "        return float(hell[0])*1000\n",
    "    else:\n",
    "        return float(hell[0])   \n",
    "with open('text.html', 'r', encoding='utf-8') as f:\n",
    "    source = f.read()\n",
    "def findName(html):\n",
    "    soup =bs(html, 'html.parser')\n",
    "    name1=soup.title.get_text()\n",
    "    name2 = name1.replace('(2)', \"\")\n",
    "    name3 = name2.replace(' | Facebook', '')\n",
    "    return name3\n",
    "def findInfo(html):\n",
    "    soup = bs(html, 'html.parser')\n",
    "    test = soup.find_all('div', class_='rq0escxv l9j0dhe7 du4w35lb j83agx80 cbu4d94t d2edcug0 hpfvmrgz rj1gh0hx buofh1pr g5gj957u o8rfisnq p8fzw8mz pcp91wgn iuny7tx3 ipjc6fyt')\n",
    "    array = []\n",
    "    for thing in test:\n",
    "        if \"instagram\" not in str(thing) and'twitter' not in str(thing) and 'facebook' not in thing.get_text():\n",
    "            array.append(thing.get_text())\n",
    "    array = np.array(array)\n",
    "    array1 = np.unique(array)\n",
    "    dict = {\"Hometown\":\"\", 'Current_town':\"\", \"Job\": []}\n",
    "    if array1.size == 0:\n",
    "        return dict\n",
    "    for item in array1:\n",
    "        if 'From' in item:\n",
    "            dict[\"Hometown\"] = item.split(\"From\")[1]\n",
    "        elif \" in \" in item and not \"Studied\" in item:\n",
    "            dict[\"Current_town\"] = item.split(' in ')[1]\n",
    "        elif 'Works at ' in item or 'Worked at' in item:\n",
    "            dict[\"Job\"].append(item.split(' at ')[1])\n",
    "        elif 'Studied ' not in item and 'Went' not in item and 'From' not in item and 'Lives' not in item and not 'https' in item and ' in ' not in item and \"Pronounces\" not in item:\n",
    "            if \"It's\" not in item and \"Widowed\" not in item and \"Joined\" not in item and 'facebook' not in item and 'Divorced' not in item:\n",
    "                if ' with ' not in item and 'In ' not in item and 'relationship' not in item and 'Married' not in item and \"Followed\" not in item and \"Engaged\" not in item and \"Single\" not in item:\n",
    "                    dict[\"Job\"].append(item)\n",
    "    return dict\n",
    "def pseudo_page_count(driver):\n",
    "    for i in range(8):\n",
    "        driver.execute_script(\"window.scrollTo(0, window.scrollY + 600)\")\n",
    "        time.sleep(1)\n",
    "    source_data = driver.page_source\n",
    "    bs_data = bs(source_data, 'html.parser')\n",
    "    posts = bs_data.find_all('div', class_='du4w35lb k4urcfbm l9j0dhe7 sjgh65i0')\n",
    "    return(len(posts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox(executable_path='./geckodriver.exe')\n",
    "login(driver)\n",
    "count = 0\n",
    "newdata = pd.DataFrame()\n",
    "for idx, data in df.groupby(level='id'):\n",
    "    array = []\n",
    "    driver.get('https://www.facebook.com/profile.php?id=' + idx)\n",
    "    html = driver.page_source\n",
    "    friends = findFriends(html)\n",
    "    info = findInfo(html)\n",
    "    job = info['Job']\n",
    "    current_town = info['Current_town']\n",
    "    home_town = info['Hometown']\n",
    "    name = findName(html)\n",
    "    page_count = pseudo_page_count(driver)\n",
    "    row = pd.DataFrame(data = np.array([[idx,name,job, current_town, home_town, page_count, friends]],dtype=object),columns=['id','Name','Job','Current_town', 'Home_town', 'Page_count', 'Friends'])\n",
    "    if count%15 == 0 and count != 0:\n",
    "        time.sleep(3)\n",
    "    count +=1\n",
    "    newdata = pd.concat([newdata, row])\n",
    "driver.close()\n",
    "newdata.set_index('id', inplace=True)\n",
    "datatoexcel = pd.ExcelWriter('facebook.xlsx')\n",
    "newdata.to_excel(datatoexcel)\n",
    "datatoexcel.save()\n",
    "newdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = webdriver.Firefox(executable_path='./geckodriver.exe')\n",
    "# login(driver)\n",
    "# generalSearch(driver)\n",
    "df = getDataFrame()\n",
    "data = pd.ExcelFile('facebook.xlsx')\n",
    "newdata= data.parse('Sheet1')\n",
    "newdata\n",
    "newdata = pd.merge(df, newdata, left_on='id', right_on='id')\n",
    "newdata.set_index('id', inplace=True)\n",
    "newdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jobTest(row):\n",
    "    for job in (row['Job']):\n",
    "        if(\"Army\" in str(job).lower()):\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e01cbe90fe171ceef91dd0fe026ccc95696046c7b29a5df34acce07500878a66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
